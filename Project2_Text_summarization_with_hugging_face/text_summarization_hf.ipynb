{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af16773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3532d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4218721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall manim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62a60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy==1.26.4\n",
    "\n",
    "# !pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df3dff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade accelerate\n",
    "# !pip uninstall -y transformers accelerate\n",
    "# !pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e32793f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade datasets fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0764833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f0429",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54758f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Reek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "nltk.download(\"punkt_tab\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ae0051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58af6780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Reek\\anaconda3\\envs\\LLMs\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33443d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e604d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_samsum = load_dataset(\"knkarthick/dialogsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eff307f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "175e7c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Person1#: Hello Mrs. Parker, how have you been?\\n#Person2#: Hello Dr. Peters. Just fine thank you. Ricky and I are here for his vaccines.\\n#Person1#: Very well. Let's see, according to his vaccination record, Ricky has received his Polio, Tetanus and Hepatitis B shots. He is 14 months old, so he is due for Hepatitis A, Chickenpox and Measles shots.\\n#Person2#: What about Rubella and Mumps?\\n#Person1#: Well, I can only give him these for now, and after a couple of weeks I can administer the rest.\\n#Person2#: OK, great. Doctor, I think I also may need a Tetanus booster. Last time I got it was maybe fifteen years ago!\\n#Person1#: We will check our records and I'll have the nurse administer and the booster as well. Now, please hold Ricky's arm tight, this may sting a little.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum['train']['dialogue'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4f13da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mrs Parker takes Ricky for his vaccines. Dr. Peters checks the record and then gives Ricky a vaccine.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum['train'][1]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a023ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vaccines'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum['train'][1]['topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe2a73d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'train_1',\n",
       " 'dialogue': \"#Person1#: Hello Mrs. Parker, how have you been?\\n#Person2#: Hello Dr. Peters. Just fine thank you. Ricky and I are here for his vaccines.\\n#Person1#: Very well. Let's see, according to his vaccination record, Ricky has received his Polio, Tetanus and Hepatitis B shots. He is 14 months old, so he is due for Hepatitis A, Chickenpox and Measles shots.\\n#Person2#: What about Rubella and Mumps?\\n#Person1#: Well, I can only give him these for now, and after a couple of weeks I can administer the rest.\\n#Person2#: OK, great. Doctor, I think I also may need a Tetanus booster. Last time I got it was maybe fifteen years ago!\\n#Person1#: We will check our records and I'll have the nurse administer and the booster as well. Now, please hold Ricky's arm tight, this may sting a little.\",\n",
       " 'summary': 'Mrs Parker takes Ricky for his vaccines. Dr. Peters checks the record and then gives Ricky a vaccine.',\n",
       " 'topic': 'vaccines'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24fdd180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split lengths: [12460, 500, 1500]\n",
      "Features: ['id', 'dialogue', 'summary', 'topic']\n"
     ]
    }
   ],
   "source": [
    "split_lengths = [len(dataset_samsum[split]) for split in dataset_samsum]\n",
    "\n",
    "print(f\"Split lengths: {split_lengths}\")\n",
    "print(f\"Features: {dataset_samsum['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e73888d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dialogue:\n",
      "#Person1#: Ms. Dawson, I need you to take a dictation for me.\n",
      "#Person2#: Yes, sir...\n",
      "#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\n",
      "#Person2#: Yes, sir. Go ahead.\n",
      "#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\n",
      "#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\n",
      "#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\n",
      "#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\n",
      "#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\n",
      "#Person2#: This applies to internal and external communications.\n",
      "#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\n",
      "#Person2#: Is that all?\n",
      "#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\n",
      "\n",
      "Summary:\n",
      "In order to prevent employees from wasting time on Instant Message programs, #Person1# decides to terminate the use of those programs and asks Ms. Dawson to send out a memo to all employees by the afternoon.\n",
      "\\Topic:\n",
      "company policy\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDialogue:\")\n",
    "print(dataset_samsum[\"test\"][1][\"dialogue\"])\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(dataset_samsum[\"test\"][1][\"summary\"])\n",
    "\n",
    "print(\"\\Topic:\")\n",
    "print(dataset_samsum[\"test\"][1][\"topic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "892636a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(example_batch):\n",
    "    # Prepend topic to dialogue input\n",
    "    input_text = [\"Topic: \" + t + \" Dialogue: \" + d for t, d in zip(example_batch[\"topic\"], example_batch[\"dialogue\"])]\n",
    "    \n",
    "    input_encodings = tokenizer(input_text, max_length=1024, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(example_batch['summary'], max_length=128, truncation=True)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_encodings['input_ids'],\n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'labels': target_encodings['input_ids']\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d69ff61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305942b5414c41ce97a0f96aa818c190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Reek\\anaconda3\\envs\\LLMs\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3921: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2107c9dffc488794e4eaa7b228f107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbdb36d1a3d474d8106101d12023600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d46a5d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 12460\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum_pt['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebf0d07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21916,\n",
       " 151,\n",
       " 16595,\n",
       " 30275,\n",
       " 151,\n",
       " 1768,\n",
       " 33892,\n",
       " 740,\n",
       " 4009,\n",
       " 151,\n",
       " 8087,\n",
       " 5390,\n",
       " 107,\n",
       " 9235,\n",
       " 108,\n",
       " 199,\n",
       " 133,\n",
       " 119,\n",
       " 174,\n",
       " 152,\n",
       " 1768,\n",
       " 33892,\n",
       " 522,\n",
       " 4009,\n",
       " 151,\n",
       " 8087,\n",
       " 982,\n",
       " 107,\n",
       " 22579,\n",
       " 107,\n",
       " 1205,\n",
       " 1226,\n",
       " 2041,\n",
       " 119,\n",
       " 107,\n",
       " 26091,\n",
       " 111,\n",
       " 125,\n",
       " 127,\n",
       " 264,\n",
       " 118,\n",
       " 169,\n",
       " 16595,\n",
       " 107,\n",
       " 1768,\n",
       " 33892,\n",
       " 740,\n",
       " 4009,\n",
       " 151,\n",
       " 3695,\n",
       " 210,\n",
       " 107,\n",
       " 1593,\n",
       " 131,\n",
       " 116,\n",
       " 236,\n",
       " 108,\n",
       " 992,\n",
       " 112,\n",
       " 169,\n",
       " 19138,\n",
       " 1093,\n",
       " 108,\n",
       " 26091,\n",
       " 148,\n",
       " 915,\n",
       " 169,\n",
       " 30047,\n",
       " 554,\n",
       " 108,\n",
       " 41586,\n",
       " 34068,\n",
       " 116,\n",
       " 111,\n",
       " 48376,\n",
       " 596,\n",
       " 3901,\n",
       " 107,\n",
       " 285,\n",
       " 117,\n",
       " 1265,\n",
       " 590,\n",
       " 459,\n",
       " 108,\n",
       " 167,\n",
       " 178,\n",
       " 117,\n",
       " 640,\n",
       " 118,\n",
       " 48376,\n",
       " 202,\n",
       " 108,\n",
       " 8097,\n",
       " 49042,\n",
       " 111,\n",
       " 2587,\n",
       " 1483,\n",
       " 6366,\n",
       " 3901,\n",
       " 107,\n",
       " 1768,\n",
       " 33892,\n",
       " 522,\n",
       " 4009,\n",
       " 151,\n",
       " 463,\n",
       " 160,\n",
       " 24387,\n",
       " 7655,\n",
       " 111,\n",
       " 14663,\n",
       " 9020,\n",
       " 152,\n",
       " 1768,\n",
       " 33892,\n",
       " 740,\n",
       " 4009,\n",
       " 151,\n",
       " 1894,\n",
       " 108,\n",
       " 125,\n",
       " 137,\n",
       " 209,\n",
       " 361,\n",
       " 342,\n",
       " 219,\n",
       " 118,\n",
       " 239,\n",
       " 108,\n",
       " 111,\n",
       " 244,\n",
       " 114,\n",
       " 932,\n",
       " 113,\n",
       " 899,\n",
       " 125,\n",
       " 137,\n",
       " 15079,\n",
       " 109,\n",
       " 1004,\n",
       " 107,\n",
       " 1768,\n",
       " 33892,\n",
       " 522,\n",
       " 4009,\n",
       " 151,\n",
       " 4810,\n",
       " 108,\n",
       " 255,\n",
       " 107,\n",
       " 7167,\n",
       " 108,\n",
       " 125,\n",
       " 311,\n",
       " 125,\n",
       " 163,\n",
       " 218,\n",
       " 217,\n",
       " 114,\n",
       " 41586,\n",
       " 34068,\n",
       " 116,\n",
       " 17581,\n",
       " 107,\n",
       " 2882,\n",
       " 166,\n",
       " 125,\n",
       " 419,\n",
       " 126,\n",
       " 140,\n",
       " 1556,\n",
       " 10645,\n",
       " 231,\n",
       " 754,\n",
       " 147,\n",
       " 1768,\n",
       " 33892,\n",
       " 740,\n",
       " 4009,\n",
       " 151,\n",
       " 184,\n",
       " 138,\n",
       " 553,\n",
       " 150,\n",
       " 2125,\n",
       " 111,\n",
       " 125,\n",
       " 131,\n",
       " 267,\n",
       " 133,\n",
       " 109,\n",
       " 6400,\n",
       " 15079,\n",
       " 111,\n",
       " 109,\n",
       " 17581,\n",
       " 130,\n",
       " 210,\n",
       " 107,\n",
       " 1032,\n",
       " 108,\n",
       " 528,\n",
       " 1137,\n",
       " 26091,\n",
       " 131,\n",
       " 116,\n",
       " 3714,\n",
       " 3820,\n",
       " 108,\n",
       " 136,\n",
       " 218,\n",
       " 26800,\n",
       " 114,\n",
       " 332,\n",
       " 107,\n",
       " 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum_pt['train']['input_ids'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0273dd48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum_pt['train']['attention_mask'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "802a041e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5390,\n",
       " 9235,\n",
       " 839,\n",
       " 26091,\n",
       " 118,\n",
       " 169,\n",
       " 16595,\n",
       " 107,\n",
       " 982,\n",
       " 107,\n",
       " 22579,\n",
       " 5723,\n",
       " 109,\n",
       " 1093,\n",
       " 111,\n",
       " 237,\n",
       " 1106,\n",
       " 26091,\n",
       " 114,\n",
       " 10733,\n",
       " 107,\n",
       " 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum_pt['train']['labels'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd107c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da1e0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall transformers -y\n",
    "# !pip install transformers==4.40.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bca83e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.40.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12ea9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "trainer_args = TrainingArguments(\n",
    "    output_dir='pegasus-samsum',\n",
    "    num_train_epochs=1,\n",
    "    warmup_steps=500,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=500,\n",
    "    save_steps=1e6,\n",
    "    gradient_accumulation_steps=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5db7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model_pegasus, args=trainer_args,\n",
    "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
    "                  train_dataset=dataset_samsum_pt[\"test\"],\n",
    "                  eval_dataset=dataset_samsum_pt[\"validation\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3814f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2911ed4c514d768e515450e2d0492e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2639, 'grad_norm': 20.45037841796875, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.11}\n",
      "{'loss': 3.1594, 'grad_norm': 14.561914443969727, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.21}\n",
      "{'loss': 3.0684, 'grad_norm': 11.114509582519531, 'learning_rate': 3e-06, 'epoch': 0.32}\n",
      "{'loss': 2.8204, 'grad_norm': 14.0777587890625, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.43}\n",
      "{'loss': 2.6146, 'grad_norm': 16.843915939331055, 'learning_rate': 5e-06, 'epoch': 0.53}\n",
      "{'loss': 2.7313, 'grad_norm': 21.220874786376953, 'learning_rate': 6e-06, 'epoch': 0.64}\n",
      "{'loss': 2.3978, 'grad_norm': 17.45792579650879, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.75}\n",
      "{'loss': 2.3615, 'grad_norm': 35.11902618408203, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.85}\n",
      "{'loss': 2.3038, 'grad_norm': 7.875046253204346, 'learning_rate': 9e-06, 'epoch': 0.96}\n",
      "{'train_runtime': 2741.1847, 'train_samples_per_second': 0.547, 'train_steps_per_second': 0.034, 'train_loss': 2.7293900520570817, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=93, training_loss=2.7293900520570817, metrics={'train_runtime': 2741.1847, 'train_samples_per_second': 0.547, 'train_steps_per_second': 0.034, 'total_flos': 909278332846080.0, 'train_loss': 2.7293900520570817, 'epoch': 0.992})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6682521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def generate_batch_sized_chunks(list_of_elements, batch_size):\n",
    "    \"\"\"\n",
    "    Split the dataset into smaller batches that we can process simultaneously.\n",
    "    Yield successive batch-sized chunks from list_of_elements.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "121fb227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'test_0_1',\n",
       " 'dialogue': \"#Person1#: Ms. Dawson, I need you to take a dictation for me.\\n#Person2#: Yes, sir...\\n#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\\n#Person2#: Yes, sir. Go ahead.\\n#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\\n#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\\n#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\\n#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\\n#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\\n#Person2#: This applies to internal and external communications.\\n#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\\n#Person2#: Is that all?\\n#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\",\n",
       " 'summary': 'Ms. Dawson helps #Person1# to write a memo to inform every employee that they have to change the communication method and should not use Instant Messaging anymore.',\n",
       " 'topic': 'communication method'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8669287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n",
    "                                batch_size=16, device=device,\n",
    "                                column_text=\"dialogue\",\n",
    "                                column_summary=\"summary\"):\n",
    "    \n",
    "    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(zip(article_batches, target_batches), total=len(article_batches)):\n",
    "        inputs = tokenizer(article_batch, max_length=1024, truncation=True,\n",
    "                        padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "        summaries = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"].to(device),\n",
    "            attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "            length_penalty=0.8,\n",
    "            num_beams=8,\n",
    "            max_length=128\n",
    "        )\n",
    "\n",
    "        # Finally, we decode the generated texts,\n",
    "    # replace the <pad> token, and add the decoded texts with the references to the metric.\n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                            clean_up_tokenization_spaces=True)\n",
    "                            for s in summaries]\n",
    "\n",
    "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
    "\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "    # Finally compute and return the ROUGE scores.\n",
    "    score = metric.compute()\n",
    "    return score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f52aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_metric = evaluate.load('rouge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788fd2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [04:52<00:00, 146.09s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'mid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m score \u001b[38;5;241m=\u001b[39m calculate_metric_on_test_ds(\n\u001b[0;32m      2\u001b[0m     dataset_samsum[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m][:\u001b[38;5;241m10\u001b[39m],  \u001b[38;5;66;03m# or full dataset_samsum[\"test\"]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     rouge_metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# or 'cpu'\u001b[39;00m\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m rouge_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmeasure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrouge_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(rouge_dict, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpegasus\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[38], line 11\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m score \u001b[38;5;241m=\u001b[39m calculate_metric_on_test_ds(\n\u001b[0;32m      2\u001b[0m     dataset_samsum[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m][:\u001b[38;5;241m10\u001b[39m],  \u001b[38;5;66;03m# or full dataset_samsum[\"test\"]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     rouge_metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# or 'cpu'\u001b[39;00m\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m rouge_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((rn, \u001b[43mscore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmid\u001b[49m\u001b[38;5;241m.\u001b[39mfmeasure) \u001b[38;5;28;01mfor\u001b[39;00m rn \u001b[38;5;129;01min\u001b[39;00m rouge_names)\n\u001b[0;32m     13\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(rouge_dict, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpegasus\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'mid'"
     ]
    }
   ],
   "source": [
    "score = calculate_metric_on_test_ds(\n",
    "    dataset_samsum[\"test\"][:10],  # or full dataset_samsum[\"test\"]\n",
    "    rouge_metric,\n",
    "    trainer.model,\n",
    "    tokenizer,\n",
    "    batch_size=8,\n",
    "    device='cuda'  # or 'cpu'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29004276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rouge1  rouge2  rougeL  rougeLsum\n",
       "pegasus  0.0051     0.0  0.0051     0.0049"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_dict = {rn: round(score[rn], 4) for rn in rouge_names}\n",
    "\n",
    "\n",
    "pd.DataFrame(rouge_dict, index=[f'pegasus'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f0d474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tokenizer\\\\tokenizer_config.json',\n",
       " 'tokenizer\\\\special_tokens_map.json',\n",
       " 'tokenizer\\\\spiece.model',\n",
       " 'tokenizer\\\\added_tokens.json',\n",
       " 'tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pegasus.save_pretrained(\"pegasus_dialogsum\")\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a3fb3",
   "metadata": {},
   "source": [
    "# for custom tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "009aab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue:\n",
      "#Person1#: Ms. Dawson, I need you to take a dictation for me.\n",
      "#Person2#: Yes, sir...\n",
      "#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\n",
      "#Person2#: Yes, sir. Go ahead.\n",
      "#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\n",
      "#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\n",
      "#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\n",
      "#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\n",
      "#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\n",
      "#Person2#: This applies to internal and external communications.\n",
      "#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\n",
      "#Person2#: Is that all?\n",
      "#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\n",
      "\n",
      "Generated Summary:\n",
      "All office communications are restricted to email correspondence and official memos.<n>The use of Instant Message programs by employees during working hours is strictly prohibited.<n>Employees who persist in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination.\n",
      "\n",
      "Reference Summary:\n",
      "Ms. Dawson helps #Person1# to write a memo to inform every employee that they have to change the communication method and should not use Instant Messaging anymore.\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./tokenizer\")\n",
    "\n",
    "# Prediction\n",
    "gen_kwargs = {\n",
    "    \"length_penalty\": 0.8, # close to 1 long output close to 0 short output\n",
    "    \"num_beams\": 8,\n",
    "    \"max_length\": 128\n",
    "}\n",
    "\n",
    "# Sample input and reference from SAMSum\n",
    "sample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\n",
    "reference = dataset_samsum[\"test\"][0][\"summary\"]\n",
    "\n",
    "# Create summarization pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# pipe = pipeline(\"summarization\", model=\"pegasus-samsum-model\", tokenizer=tokenizer)\n",
    "pipe = pipeline(\"summarization\", model=\"./pegasus_dialogsum\", tokenizer=tokenizer)\n",
    "\n",
    "# pipe = pipeline(\"summarization\", model=\"google/pegasus-samsum\", tokenizer=\"google/pegasus-samsum\")\n",
    "\n",
    "\n",
    "# Display input dialogue\n",
    "print(\"Dialogue:\")\n",
    "print(sample_text)\n",
    "\n",
    "# Generate summary\n",
    "generated_summary = pipe(sample_text)[0]['summary_text']\n",
    "\n",
    "# Display result\n",
    "print(\"\\nGenerated Summary:\")\n",
    "print(generated_summary)\n",
    "\n",
    "print(\"\\nReference Summary:\")\n",
    "print(reference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da48a3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary:\n",
      "All office communications are restricted to email correspondence and official memos.<n>The use of Instant Message programs by employees during working hours is strictly prohibited.<n>Employees who persist in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel Summary:\")\n",
    "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8c5b17",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
